<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>数据库 on 寻雾启示</title>
        <link>http://localhost:1313/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
        <description>Recent content in 数据库 on 寻雾启示</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Fri, 10 Jan 2025 21:07:27 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>【读点论文】Amazon Aurora:Design Considerations for High Throughput Cloud-Native Relational Databases?</title>
        <link>http://localhost:1313/posts/aurora%E8%AE%BA%E6%96%87/</link>
        <pubDate>Fri, 10 Jan 2025 21:07:27 +0800</pubDate>
        
        <guid>http://localhost:1313/posts/aurora%E8%AE%BA%E6%96%87/</guid>
        <description>&lt;p&gt;Aurora 主要做了三方面的改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大规模集群化的持久化保证&lt;/li&gt;
&lt;li&gt;日志即数据库&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;大规模集群下的持久化&#34;&gt;大规模集群下的持久化
&lt;/h3&gt;&lt;h4 id=&#34;跨-availability-zone-的-quorum-机制&#34;&gt;跨 Availability Zone 的 Quorum 机制
&lt;/h4&gt;&lt;p&gt;为了提高可用性，数据需要被备份到多个节点，但这会带来数据一致性问题。在分布式系统中，该问题通常是通过 quorum 机制来解决。&lt;/p&gt;
&lt;p&gt;Quorum 机制（法定人数机制） 是指在分布式系统中，必须有至少一定数量的节点同意某个操作，该操作才会被执行。为了满足一致性要求，quorum 机制需要满足以下条件：&lt;/p&gt;
&lt;p&gt;假设有 n 个节点，写入需要 w 个节点确认，读需要至少 r 个节点确认，则&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;w + r &amp;gt; n&lt;/strong&gt;：如果满足，说明读节点和写节点肯定是有交集的，因此读节点中一定有节点包含最新值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;w &amp;gt; n/2&lt;/strong&gt;：表示至少有一半以上的节点写入成功，从而保证数据读取时一定会读到最新的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个常见的节点设置是 n 为 3 或 5，w = r = n/2 + 1。&lt;/p&gt;
&lt;h4 id=&#34;quorum-机制的不足&#34;&gt;Quorum 机制的不足
&lt;/h4&gt;&lt;p&gt;AWS 有可用区（AZ，Availability Zone）的概念，每个 AZ 相对独立，但共享低延迟网络。&lt;/p&gt;
&lt;p&gt;上面提到的 Quorum 机制无法应对可用区级别的故障。如果 n 个节点在同一个 AZ 中，那么当 AZ 发生故障时，所有节点都会受到影响，服务将完全不可用。如果 n 个节点分布在 a、b、c 三个 AZ 中，那么当 a 可用区发生故障时，Quorum 机制也会失效。&lt;/p&gt;
&lt;p&gt;为了解决上述问题，Aurora 引入了 3 可用区 + 6 副本的 Quorum 机制:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个数据有 6 个副本，分布在 3 个 AZ 中（每个 AZ 内 2 个副本）&lt;/li&gt;
&lt;li&gt;写 Quorum 需要 4 个副本确认&lt;/li&gt;
&lt;li&gt;读 Quorum 需要 3 个副本确认&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种跨 AZ 的 Quorum 机制可以做到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于写操作，可以容忍任意两个节点发生故障。比如某个 AZ 完全失效，或者两个 AZ 中分别有一个节点发生故障。&lt;/li&gt;
&lt;li&gt;对于读操作，可以容忍任意一个 AZ + 任意一个节点发生故障。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;分段存储--快速恢复&#34;&gt;分段存储 &amp;amp; 快速恢复
&lt;/h3&gt;&lt;p&gt;我们通常用如下公式来衡量系统的可用性：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Availability = MTTF（Mean Time To Failure） / (MTTF + MTTR（Mean Time To Recovery）)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在分布式系统中，故障是必然的且难以预测的，因此为了提高系统的可用性，需要尽可能减少故障的恢复时间。为了方便快速恢复，Aurora 采用了**分段存储（Segmented Storage）**的机制。Aurora 将数据切分为 10GB 大小的段，每 6 个段组成一个 保护组（PG，Protection Group），组中的 Segment 分布在 3 个 AZ 中，每个 AZ 有两个 Segment。保护组存储在挂载了 SSD 的 EC2 实例中，众多 PG 组成一个存储卷（Volume），Volume 最大容量为 60TB（注：新版本已经支持到了 128TB）。&lt;/p&gt;
&lt;p&gt;Aurora 以 Segment 为单位进行故障恢复，在 10Gbps 带宽下，恢复一个 Segment 只需要大约 10 秒钟的时间。在这种情况下，如果存在故障导致 Quorum 机制失效，需要在 10s 内出现以下故障：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同时发生 2 个不相关的故障&lt;/li&gt;
&lt;li&gt;与故障不相关的 AZ 发生故障&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实际场景中，这种故障发生的概率非常低。因此 Aurora 也宣称提供了 99.99% 的可用性。&lt;/p&gt;
&lt;h3 id=&#34;弹力设计的优势&#34;&gt;弹力设计的优势
&lt;/h3&gt;&lt;p&gt;引用论文中的话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Once one has designed a system that is naturally resilient to long failures, it is naturally also resilient to shorter ones. A storage system that can handle the long-term loss of an AZ can also handle a brief outage due to a power event or bad software deployment requiring rollback
如果你设计了一个能够容忍长期故障的系统，那么它自然也能够容忍短期的故障。一个能够容忍 AZ 长期故障的存储系统，也能够容忍由于电源故障或软件部署失败导致的短暂故障。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Aurora 的弹力设计可以为运维带来非常大的便利性。比如如果某个节点成为了 hot node，那么可以节点中的 segment 或者整个节点标记为不可用，然后快速将 segment 迁移到其他节点。或者某些节点需要进行软件升级、打补丁等操作，也可以按计划在 AZ 中进行，甚至可以使用 CICD 来实现快速发布。&lt;/p&gt;
&lt;h2 id=&#34;日志即数据库&#34;&gt;日志即数据库
&lt;/h2&gt;&lt;h3 id=&#34;写放大&#34;&gt;写放大
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://pub-08b57ed9c8ce4fadab4077a9d577e857.r2.dev/aurora-003.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>【读点论文】What’s Really New with NewSQL?</title>
        <link>http://localhost:1313/posts/newsql%E8%AE%BA%E6%96%87/</link>
        <pubDate>Fri, 10 Jan 2025 21:07:27 +0800</pubDate>
        
        <guid>http://localhost:1313/posts/newsql%E8%AE%BA%E6%96%87/</guid>
        <description>&lt;p&gt;本篇论文是 2016 年 CMU 发表介绍 NewSQL 发展的一篇综述论文，论文主要对新兴的 NewSQL 数据库的起源、分类以及主要技术原理做了介绍，其中对数据库发展历史、NewSQL 实现原理的介绍非常值得一读。&lt;/p&gt;
&lt;h2 id=&#34;数据库发展简史&#34;&gt;数据库发展简史
&lt;/h2&gt;&lt;p&gt;论文首先简要梳理了数据库的发展历程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 1960 年代 ~ 1970 年代：数据库的诞生&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;早在 1960 年代，IBM 为了支持阿波罗计划，开发了 IMS 来存储数据，引入了&lt;strong&gt;代码与数据分离&lt;/strong&gt;的思想，让开发者可以专注于操作数据，无需关心这些操作的底层实现细节。&lt;/p&gt;
&lt;p&gt;在之后的 1970 年代，作为关系型数据库的先驱，IBM 的 System R 和加州大学的 INGRES 数据库诞生，后者被其他大学广泛使用，并在之后被商业化。与此同时，Oracle 发布了其第一版的 DBMS。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 1980-1990 年代：创新与开源&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1980 年代，IBM 发布了 DB2 数据库，与此同时还有 Sybase、Informix 等商业产品进入市场，推动着关系型数据库的普及。&lt;/p&gt;
&lt;p&gt;在 1980 年代末、1990 年代初，有一股面向对象数据库设计的浪潮，旨在克服关系型数据库和面向对象编程语言之间的不匹配。虽然此类数据库没有成为主流，但在此过程中的许多技术创新为后来 XML 数据存储、对象存储以及 NoSQL 文档数据库的设计奠定了基础。&lt;/p&gt;
&lt;p&gt;到了 1990 年代，开源数据库项目兴起，当前流行的 MySQL 和 PostgreSQL 数据库均在此期间诞生。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 2000 年代：互联网推动数据库革新&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;互联网迅猛发展，互联网应用对高并发和高可用的需求，让传统数据库成为瓶颈。虽然可以通过垂直扩展来解决，但这种方法存在局限性，并且从低配机器向高配机器迁移数据的成本也非常高。&lt;/p&gt;
&lt;p&gt;为了克服这些限制，Google、eBay 等公司开始采用 middleware 中间件的方式，将多台机器上的单点数据库组合起来，通过 middleware 做代理，实现跨机器的操作，但这种方式对复杂的查询和事务支持有限，有时候开发者有时候需要自己来维护数据处理逻辑。像 eBay 的 middleware 组件就要求开发者自己实现相关的事务和复杂查询。&lt;/p&gt;
&lt;p&gt;总的来看，现阶段的关系型数据库面临三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;关系型数据库的核心是 ACID，其关注重点在事务一致性和数据的正确性，而这是以可用性和性能为代价的。与互联网应用需要面对的高并发、高可用、高性能的需求不匹配。&lt;/li&gt;
&lt;li&gt;与互联网应用一起而来的还有海量的数据，使用像 MySQL 这样的数据库存储海量数据是非常不明智的选择。&lt;/li&gt;
&lt;li&gt;关系型数据库的数据建模和互联网应用所需的数据模型往往并不匹配，有时候需要更灵活、适配的建模方案。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上问题最终催生了 NoSQL 数据库的诞生。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. NoSQL 的崛起&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NoSQL 数据库最大的特点就是放弃了对 ACID 强一致性的支持，转而追求最终一致性。数据模型也更加的灵活，比如可以是键值对、文档模型或者图数据库等&lt;/p&gt;
&lt;p&gt;Google的 BigTable、Amazon 的 Dynamo，以及后来的 Cassandra、MongoDB、ElasticSearch 等开源产品都可以归类为 NoSQL 数据库。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. NoSQL 的局限与 NewSQL 的诞生&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NoSQL 数据库虽然解决了传统关系型数据库的很多问题，但同时也带来了新的问题。许多企业应用（如金融系统）要求必须做到强一致性，同时又需要 NoSQL 所带来的高性能、高可用、可扩展性。为此，结合了传统数据库的强一致性和 NoSQL 的高性能、高可用、可扩展特性的数据库应运而生，此类数据库被称为 NewSQL 数据库。&lt;/p&gt;
&lt;h2 id=&#34;newsql-的定义与分类&#34;&gt;NewSQL 的定义与分类
&lt;/h2&gt;&lt;h3 id=&#34;newsql-的定义&#34;&gt;NewSQL 的定义
&lt;/h3&gt;&lt;p&gt;论文中对 NewSQL 的定义如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;They are a class of modern relational DBMSs that seek to provide the same scalable performance of NoSQL for OLTP read-write workloads while still maintaining ACID guarantees for transactions.
它们是一类现代关系型 DBMS，旨在为 OLTP 读写工作负载提供与NoSQL相同的可扩展性能，同时仍然为事务保持ACID保证。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来书就是，NewSQL 既有传统关系型数据库的 ACID 保证，又兼具了 NoSQL 可扩展性。&lt;/p&gt;
&lt;p&gt;还有一种更狭义的定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;a lock-free concurrency control scheme and&lt;/li&gt;
&lt;li&gt;a shared-nothing distributed architecture [57]&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;NewSQL 大致可以分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;New Architecture&lt;/strong&gt;：采用新的架构设计，从零开发的新数据库&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transparent Sharding Middleware&lt;/strong&gt;：基于中间件实现，对开发者透明&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Database&lt;/strong&gt;：云厂商提供的 NewSQL 数据库&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;new-sql-实现原理&#34;&gt;New SQL 实现原理
&lt;/h2&gt;&lt;p&gt;这部分是论文的重点，对 NewSQL 相关的实现原理做了介绍。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
